### 웹 크롤러

#### 목표

> 네이버에서 가져올 내용은 크게 4 가지 데이터 셋(리뷰 정보, 아이템 정보, 브랜드 정보, 카테고리 정보)으로, 이를 가져오는 것이 목표

#### 구성

> 이를 네이버 서버에서 받아오고(1), 의미 단위로 정보를 쪼개고(2), 이를 저장하는 것(3)으로 구성

#### 핵심 문제

1. 서버에서 데이터를 가져올 때의 지연 시간은 유동적이며, 느리다. 데이터를 가져오는 시간을 최소화하면서, 네이버 서버의 부하가 많이 가지지 않도록 하는 것이 필요하다
2. 서버와의 통신상황에서는 예외가 존재하고, 네이버 서버는 계속 자신의 웹페이지를 유동적으로 바꾼다. 이에 대비할 수 있도록, 예외 상황들을 잘 잡아낼 필요가 있다.
3. 엘라스틱 서치는 잘 다루어본 적이 없는 DB이므로, 저장소인 엘라스틱 서치의 Data I/O 문제를 단순화 시켜야 한다.

#### 해결 방안

1. 서버에서 데이터를 가져오는 프로세스와 그 데이터를 파싱하는 프로세스를 분리하여, 파싱하는 작업과 가져오는 작업을 동시에 진행할 수 있도록 한다. 서버에서 데이터를 가져오는 시간은 최소 딜레이 시간을 지키면서 가져오도록 설계한다.
2. 파싱 결과에 대한 예외처리를 잡아내고, 예외상황에 대한 로그를 저장한다. 예외 상황이 발생한 경우, 그 예외를 개발자에게 알려준다.
3. 엘라스틱 서치와 크롤러 사이에 중간 저장소로 Redis 저장소를 이용한다. 간편한 인터페이스와 빠른 응답속도로 이루어져 있다. 

#### 구조

크게 크롤러(Crawler) / 큐 (queue) / 파서(parser) / 세이버(saver) 로 이루어져 있다.

* 크롤러 : 서버에서 데이터를 가져와서, 큐에 담는 역할
* 큐 : 크롤러와 파서 사이에서 데이터를 관리하는 역할
* 파서 : 가져온 데이터를, 의미있는 단어로 쪼개 json으로 변환하는 역할
* 세이버 : 파서의 결과물을 저장소로 저장하는 역할

디자인 패턴은 생산자/ 소비자 패턴으로 디자인되었다.

그 외로, 

* 로거 : 크롤러와 파서에서 발생한 예외 상황들을 감시하는 역할

로 구성되어 있다.