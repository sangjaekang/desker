{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#리뷰 데이터\n",
    "review_df = pd.read_csv(\"../data/reviews.csv\", delimiter=\"▒\",engine='python')\n",
    "#item 데이터\n",
    "item_df = pd.read_csv(\"../data/item.csv\", delimiter=\"▒\",engine='python')\n",
    "#category 데이터\n",
    "cat_df = pd.read_csv(\"../data/category.csv\", delimiter=\"▒\",engine='python')\n",
    "#Brand 데이터\n",
    "brand_df = pd.read_csv(\"../data/brand.csv\", delimiter=\"▒\",engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_int(num):\n",
    "    try:\n",
    "        return int(num)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def normalize_price(price):\n",
    "    if isinstance(price,int):   \n",
    "        return price    \n",
    "    try:\n",
    "        price = price.replace(\",\",\"\").strip()\n",
    "    except AttributeError as e:\n",
    "        print(\"price : \",price,e)\n",
    "    if price[-1] == '원':\n",
    "        return int(price[:-1])\n",
    "    else:\n",
    "        try:\n",
    "            return int(price)\n",
    "        except ValueError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category dataframe 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_df[['cat1_id','cat2_id','cat3_id','cat4_id']] =\\\n",
    "cat_df[['cat1_id','cat2_id','cat3_id','cat4_id']].applymap(normalize_int)\n",
    "\n",
    "cat_df[['cat1_title','cat2_title','cat3_title','cat4_title']] =\\\n",
    "cat_df[['cat1_title','cat2_title','cat3_title','cat4_title']].applymap(\n",
    "lambda x : \"\" if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item dataframe 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_df[['min_price','max_price']] =\\\n",
    "item_df[['min_price','max_price']].applymap(normalize_price)\n",
    "\n",
    "item_df['reg_date'] = item_df.reg_date.apply(lambda x : x[:-1] if x[-1]=='.' else x)\n",
    "item_df['reg_date'] = pd.to_datetime(item_df.reg_date, format=\"%Y.%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memoize(func):\n",
    "    cache = {}\n",
    "    def memoizer(*args, **kwargs):\n",
    "        key = str(args) + str(kwargs)\n",
    "        if key not in cache:\n",
    "            cache[key] = func(*args, **kwargs)\n",
    "        return cache[key]\n",
    "    return memoizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_category(index, categories):\n",
    "    try:\n",
    "        cat_name = categories.split('>')[index]\n",
    "        return cat_name\n",
    "    except IndexError as e:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize\n",
    "def find_similar(match_list, input_str):\n",
    "    series = pd.Series()\n",
    "    for target_str in match_list:\n",
    "        series[target_str] = SequenceMatcher(None, input_str, target_str).ratio()\n",
    "    return series.sort_values(ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이름을 쪼개서 나누어 넣음\n",
    "for i in range(1,5):\n",
    "    item_df['cat{}_title'.format(i)] = item_df.raw_category.apply(partial(split_category, i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이름이 따로 없는 경우에는 가장 가까운 단어를 찾아서 넣어줌\n",
    "for i in range(1,5):\n",
    "    cat_title = \"cat{}_title\".format(i)\n",
    "    cat_list = list(cat_df[cat_title].unique())\n",
    "    not_in_category = ~item_df[cat_title].isin(cat_df[cat_title].unique())\n",
    "    if not_in_category.sum() > 0:\n",
    "        item_df.loc[not_in_category,cat_title] =\\\n",
    "        item_df.loc[not_in_category,cat_title].apply(partial(find_similar,cat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check category name\n",
    "for i in range(1,5):\n",
    "    unique_set = set(item_df['cat{}_title'.format(i)]) - set(cat_df['cat{}_title'.format(i)])\n",
    "    assert len(unique_set) == 0,\\\n",
    "    \"[category level:{}] not Exist in category dataFrame---{}\".format(i, unique_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review dataframe 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_df['review_date'] = pd.to_datetime(review_df['review_date'],format=('%Y.%m.%d.'))\n",
    "review_df['review_grade'] = review_df.review_grade.astype(int)\n",
    "review_df['item_id'] = review_df.item_id.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Merging 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(review_df, item_df, how='inner', left_on='item_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"../data/merge.csv\",sep=\"▒\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_sentence = review_df.iloc[0]['review_atc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse phrase to porphemes\n",
    "print(twitter.morphs(target_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun extractor\n",
    "print(twitter.nouns(target_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrase extractor\n",
    "print(twitter.phrases(target_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagger\n",
    "print(twitter.pos(target_sentence,norm=True))\n",
    "print('\\n--------------------------------------------------------------\\n')\n",
    "print(twitter.pos(target_sentence,norm=True,stem=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "norm - 정규화(normalization)\n",
    "    \n",
    "    한국어를 처리하는 예시입니닼ㅋㅋ -> 한국어를 처리하는 예시입니다ㅋㅋ\n",
    "\n",
    "stem - 어근화(stemming)\n",
    "\n",
    "    한국어를 처리하는 예시입니다 ㅋㅋ -> 한국어Noun, 를Josa, 처리Noun, 하다verb, 예시Noun, 이다Adjective, ㅋㅋKorean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구문 분석\n",
    "\n",
    "reference : http://konlpy.org/ko/v0.4.3/examples/chunking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = twitter.pos(target_sentence,norm=True,stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a chunk grammar, or chunking rules, then chunk\n",
    "grammar = \"\"\"\n",
    "NP: {<N.*>*<Suffix>?}   # Noun phrase\n",
    "VP: {<V.*>*}            # Verb phrase\n",
    "AP: {<A.*>*}            # Adjective phrase\n",
    "\"\"\"\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "chunks = parser.parse(words)\n",
    "print(\"# Print whole tree\")\n",
    "print(chunks.pprint())\n",
    "\n",
    "print(\"\\n# Print noun phrases only\")\n",
    "for subtree in chunks.subtrees():\n",
    "    if subtree.label()=='NP':\n",
    "        print(' '.join((e[0] for e in list(subtree))))\n",
    "        print(subtree.pprint())\n",
    "\n",
    "# Display the chunk tree\n",
    "chunks.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
